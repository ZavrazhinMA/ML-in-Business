{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:53.458439Z",
     "start_time": "2021-05-03T14:00:52.899982Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:53.710217Z",
     "start_time": "2021-05-03T14:00:53.460023Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:53.713537Z",
     "start_time": "2021-05-03T14:00:53.711678Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install gensim библиотека для «Тематического моделирования»\n",
    "# !pip install razdel- токенизация\n",
    "# !pip install pymorphy2 - приведение слов в нормальную форму\n",
    "# !pip install nltk - токенизация лемматизация и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:52:31.087807Z",
     "start_time": "2021-05-03T09:52:29.302696Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:54.058192Z",
     "start_time": "2021-05-03T14:00:53.714523Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:55.115378Z",
     "start_time": "2021-05-03T14:00:54.059523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# новости\n",
    "news = pd.read_csv(\"articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:55.131000Z",
     "start_time": "2021-05-03T14:00:55.116562Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим пользователей и списки последних прочитанных новостей\n",
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:55.239876Z",
     "start_time": "2021-05-03T14:00:55.132999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "print(len(stopword_ru))\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:55.245515Z",
     "start_time": "2021-05-03T14:00:55.241506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:00:55.257066Z",
     "start_time": "2021-05-03T14:00:55.247268Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:05:18.388524Z",
     "start_time": "2021-05-03T14:00:55.258570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 22s, sys: 239 ms, total: 4min 22s\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста.\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:05:29.894508Z",
     "start_time": "2021-05-03T14:05:18.391081Z"
    }
   },
   "outputs": [],
   "source": [
    "#сформируем список текстов\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:02.546470Z",
     "start_time": "2021-05-03T14:05:29.895744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 24 ms, total: 32.6 s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)#, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:02.819642Z",
     "start_time": "2021-05-03T14:06:02.548336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:02.826888Z",
     "start_time": "2021-05-03T14:06:02.820971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nn', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'играть', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.1608058),\n",
       " (8, 0.19282326),\n",
       " (11, 0.07835247),\n",
       " (20, 0.24427506),\n",
       " (22, 0.3025198)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:02.861969Z",
     "start_time": "2021-05-03T14:06:02.827928Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: риск километр болезнь объяснять сведение сша белорусский\n",
      "topic_1: столетие болгария аргентина прибегать 2030 nnnn сестра\n",
      "topic_2: век офицер мальчик нанести мышь свидетель фаза\n",
      "topic_3: золото комплексный нил красноярский статистика 1,9 победитель\n",
      "topic_4: население конкурс кровь запустить супруг фотография эксперимент\n",
      "topic_5: земля мозг станция вода новый пациент км\n",
      "topic_6: газ европа превысить северный армения эстония литва\n",
      "topic_7: погибнуть произойти тело экипаж пострадать жертва способность\n",
      "topic_8: цена ракета рост рынок эксперт млн технология\n",
      "topic_9: украина украинский задержать мужчина киев миллиард уголовный\n",
      "topic_10: военный помощь район область граница 2017 операция\n",
      "topic_11: nn место тыс рейтинг первый южный сократиться\n",
      "topic_12: 2019 строительство улица столица увеличение объект ступень\n",
      "topic_13: ребёнок россия гражданин статья газета nn писать\n",
      "topic_14: исследование экономика возраст университет анализ родитель планета\n",
      "topic_15: новый тыс большой первый автор всё уровень\n",
      "topic_16: nn москва день фестиваль мероприятие сайт праздник\n",
      "topic_17: источник миссия годовой достигать величина население отбор\n",
      "topic_18: пенсия эксперимент правительство министерство законопроект следствие данные\n",
      "topic_19: млн доллар долг университет составить задолженность сатурн\n",
      "topic_20: россия сша российский научный всё первый n—\n",
      "topic_21: nn путин nnn владимир россия китай белоруссия\n",
      "topic_22: грунт фильм музыка студия понятие терминал писать\n",
      "topic_23: млрд рубль россия проект фонд глава банк\n",
      "topic_24: обнаружить сотрудник поверхность убийство территория связанный следователь\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:02.866956Z",
     "start_time": "2021-05-03T14:06:02.862995Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция, которая будет возвращать векторное представление новости\n",
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:27.806555Z",
     "start_time": "2021-05-03T14:06:02.868643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2443</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.4449</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  \\\n",
       "0       6   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   \n",
       "1    4896   0.0000   0.0000   0.0000   0.2502   0.0000   0.0000   0.0000   \n",
       "2    4897   0.0000   0.0000   0.0000   0.1608   0.0000   0.0000   0.0000   \n",
       "3    4898   0.0000   0.0000   0.0000   0.0562   0.0000   0.0186   0.0000   \n",
       "4    4899   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   \n",
       "\n",
       "   topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0   0.0000   0.0000  ...    0.0000    0.0781    0.0661    0.0000    0.0000   \n",
       "1   0.0000   0.0000  ...    0.0000    0.0000    0.0000    0.0000    0.0000   \n",
       "2   0.0000   0.1928  ...    0.0000    0.0000    0.0000    0.0000    0.0000   \n",
       "3   0.0000   0.0000  ...    0.1771    0.0349    0.0000    0.0000    0.0000   \n",
       "4   0.0000   0.0000  ...    0.0000    0.0000    0.0000    0.0000    0.0000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0    0.0282    0.0000    0.0000    0.8193    0.0000  \n",
       "1    0.7258    0.0000    0.0000    0.0000    0.0000  \n",
       "2    0.2443    0.0000    0.3025    0.0000    0.0000  \n",
       "3    0.6392    0.0000    0.0641    0.0000    0.0000  \n",
       "4    0.3904    0.0000    0.1386    0.4449    0.0000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:27.823175Z",
     "start_time": "2021-05-03T14:06:27.807737Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.34110534,\n",
       "       0.        , 0.03112972, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12814406, 0.06438516, 0.        , 0.        ,\n",
       "       0.23586519, 0.        , 0.        , 0.06801692, 0.        ,\n",
       "       0.        , 0.11934277, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# векторные представления пользователей\n",
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))\n",
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:27.830620Z",
     "start_time": "2021-05-03T14:06:27.824738Z"
    }
   },
   "source": [
    "1. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "Повторить п.2, но используя уже не медиану, а max\n",
    "\n",
    "2. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:06:27.835320Z",
     "start_time": "2021-05-03T14:06:27.831893Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list, agg_type='mean'):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    if agg_type == 'mean':\n",
    "        user_vector = np.mean(user_vector, 0)\n",
    "    if agg_type == 'median':\n",
    "        user_vector = np.median(user_vector, 0)\n",
    "    if agg_type == 'max':\n",
    "        user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T14:32:52.719440Z",
     "start_time": "2021-05-03T14:32:51.198746Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thresholds</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fscore</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>0.8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc_score</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metrics   mean  median    max\n",
       "0     thresholds 0.2277  0.2658 0.3801\n",
       "1         fscore 0.6380  0.7117 0.8008\n",
       "2      precision 0.5361  0.6436 0.8058\n",
       "3         recall 0.7878  0.7959 0.7959\n",
       "4  roc_auc_score 0.9338  0.9626 0.9771"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = ['mean', 'median', 'max']\n",
    "result_dict = {}\n",
    "result_dict['metrics'] = ['thresholds', 'fscore', 'precision', 'recall', 'roc_auc_score']\n",
    "for agg_type in agg_list:\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(\n",
    "        lambda x: get_user_embedding(x, agg_type=agg_type), 1)])\n",
    "    user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid'] +\n",
    "                                      ['topic_{}'.format(i) for i in range(25)]]\n",
    "    \n",
    "    target = pd.read_csv(\"users_churn.csv\")\n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "    \n",
    "    # разделение на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                        X['churn'], random_state=0)\n",
    "    # обучение\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    # предсказания\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "    # метрики качества\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    result_dict[agg_type] = [thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, y_proba)]\n",
    "df_result = pd.DataFrame(result_dict)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отток в большинстве случаев определяется одной темой, важной для пользователя. При использовании mean в качестве усреднения занижается важность этой темы для (разносторонних) пользователей, которые читают новости и на другие тематики тоже. Использование max в качестве усреднения более полно характеризует интресы пользователя. Медиана - промежуточный вариант."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
